{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f1df22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. dataset of sentences to overall sentiment\n",
    "2. create a model from dataset of word to sentiment\n",
    "2.5 gramatically break down sentence instead of word by word\n",
    "3. use model for our own sentence input to output overall sentiment of sentence\n",
    "3.5 if a word is not known --> do sentiment analysis on its dictionary definition or neutralize\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6d84cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "lm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9abba92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/fdwraith/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "704c14bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"sentiment\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "df = pd.read_csv(\n",
    "    'training.1600000.processed.noemoticon.csv',\n",
    "    header=None, encoding=\"ISO-8859-1\", names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac3fa9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NEGATION_WORDS = ['not', 'no']\n",
    "STOP_WORDS = stopwords.words('english')\n",
    "\n",
    "for word in NEGATION_WORDS:\n",
    "    STOP_WORDS.remove(word)\n",
    "\n",
    "URL_PATTERN = r'((https://[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*))'\n",
    "USER_PATTERN = '@[^\\s]+'\n",
    "PUNCTUATIONS = ['!', '?']\n",
    "\n",
    "processed = []\n",
    "for sentiment, tweet in zip(df['sentiment'], df['text']):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(URL_PATTERN, '', tweet)\n",
    "    tweet = re.sub(USER_PATTERN, '', tweet)\n",
    "    for p in PUNCTUATIONS:\n",
    "        tweet = tweet.replace(p, '')\n",
    "    for sw in STOP_WORDS:\n",
    "        tweet = re.sub(r'\\b{0}\\b'.format(sw), '', tweet)\n",
    "    for w in NEGATION_WORDS:\n",
    "        tweet = re.sub(r'\\b{0} \\b'.format(w), '{0}_'.format(w), tweet)\n",
    "        \n",
    "    processed.append((sentiment, tweet))    \n",
    "    \n",
    "df = pd.DataFrame(data=processed, columns=['sentiment', 'tweet'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9c7e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, df['sentiment'], test_size = 0.05, random_state=0)\n",
    "\n",
    "model = {}\n",
    "for sentiment, tweet in zip(X_test['sentiment'], X_test['text']):\n",
    "    for word in tweet.split():\n",
    "        word = lm.lemmatize(word)\n",
    "        if word in model:\n",
    "            count, avg = model[word]\n",
    "            model[word] = (count+1, (count*avg+sentiment) / (count+1))\n",
    "        else:\n",
    "            model[word] = (1, sentiment)\n",
    "                        \n",
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
